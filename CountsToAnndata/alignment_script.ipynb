{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Dbit-seq transcriptome data and images using Squidpy tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following code ensures that all functions and init files are reloaded before executions.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load gui for napari\n",
    "#%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import issue with loess function detected. Probably due to Windows. Error ignored.\n",
      "Package 'bbknn' not installed here. Error ignored.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import dbitx_funcs as db\n",
    "import scanpy as sc\n",
    "import napari\n",
    "import cv2\n",
    "#import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameters file\n",
    "settings_file = \"../CountsToAnndata/alignment_parameters.csv\"\n",
    "lines = open(settings_file).readlines()\n",
    "param_start = [i for i, line in enumerate(lines) if line.startswith(\">parameters\")][0]\n",
    "dir_start = [i for i, line in enumerate(lines) if line.startswith(\">directories\")][0]\n",
    "\n",
    "# read settings file\n",
    "settings = pd.read_csv(settings_file, header=None)\n",
    "\n",
    "# read parameters\n",
    "parameters = pd.read_csv(settings_file, \n",
    "                       nrows=dir_start-1).dropna(how='all', axis=0).dropna(how='all', axis=1).set_index('category')\n",
    "# read directories\n",
    "directories = pd.read_csv(settings_file, \n",
    "                          skiprows=dir_start, usecols=range(1,6)).dropna(how='all', axis=0)\n",
    "# extract parameters\n",
    "channel_names = parameters.loc[\"channel_names\", \"value\"].split(\" \")\n",
    "channel_labels = parameters.loc[\"channel_labels\", \"value\"].split(\" \")\n",
    "\n",
    "# determine alignment channel\n",
    "alignment_channel = [elem for elem in channel_names if \"*\" in elem][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if all necessary parameters are in the file\n",
    "param_cats = [\"channel_names\", \"channel_labels\", \"n_channels\"]\n",
    "dir_cats = [\"input_transcriptome\", \"input_images\", \"output\", \"vertices_x\", \"vertices_y\"]\n",
    "\n",
    "assert np.all([elem in parameters.index for elem in param_cats]), \\\n",
    "    \"Not all required categories found in parameter section {}\".format(param_cats)\n",
    "assert np.all([elem in directories.columns for elem in dir_cats]), \\\n",
    "    \"Not all required column headers found in directory section {}\".format(dir_cats)\n",
    "\n",
    "# check if channel names and labels have same length\n",
    "assert len(channel_names) == len(channel_labels), \\\n",
    "    \"Numbers of channel_names and channel_labels differ.\"\n",
    "\n",
    "# check if all input images and matrix files exist\n",
    "try:\n",
    "    assert np.all([os.path.isfile(f) for f in directories[\"input_transcriptome\"]]), \\\n",
    "        \"Not all input files exist.\"\n",
    "except AssertionError as e:\n",
    "    # check which files are missing\n",
    "    missing_files = [f for f in directories[\"input_transcriptome\"] if not os.path.isfile(f)]\n",
    "    print(\"{} Following files are missing: {}\".format(e, missing_files))\n",
    "    #sys.exit()\n",
    "    exit()\n",
    "\n",
    "# check if all output names are unique\n",
    "assert len(np.unique(directories[\"output\"])) == len(directories[\"output\"]), \\\n",
    "    \"Output files are not unique. This would cause that one file is overwritten by another.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do procedure for first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "n_datasets = len(directories)\n",
    "\n",
    "vertices_list = [None]*n_datasets\n",
    "\n",
    "dirs = directories.loc[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameters for this dataset\n",
    "matrix_file = dirs[\"input_transcriptome\"]\n",
    "image_dirs = glob(dirs[\"input_images\"])\n",
    "output_file = dirs[\"output\"]\n",
    "output_dir = os.path.dirname(output_file)\n",
    "\n",
    "# check if the vertices are given in the settings file\n",
    "vertices_not_given = pd.isnull(directories.loc[i, \"vertices_x\"]) or pd.isnull(directories.loc[i, \"vertices_y\"])\n",
    "\n",
    "# check if number of images matches number of channel names\n",
    "assert len(image_dirs) == len(channel_names), \"Number of detected images does not match number of channel names in parameters file.\"\n",
    "\n",
    "# detect get alignment marker image\n",
    "alignimg_dir = [d for d in image_dirs if alignment_channel.strip(\"*\") in d][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save adata objects for this dataset\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read alignment image\n",
    "alignment_image = cv2.imread(alignimg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_not_given = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vertices_not_given:\n",
    "    ### Select corner spots in alignment image using napari viewer\n",
    "    # with napari.gui_qt():\n",
    "    # https://napari.org/guides/stable/event_loop.html#intro-to-event-loop\n",
    "    viewer = napari.view_image(alignment_image, \n",
    "        title=\"Select corner spots in alignment image {} of {} \".format(i+1, n_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vertices_not_given:\n",
    "    # fetch vertices (center points at cross points of alignment channels)\n",
    "    corner_spots_center = viewer.layers[\"Points\"].data.astype(int)\n",
    "\n",
    "    # collect corner spot\n",
    "    vertices_list[i] = corner_spots_center\n",
    "\n",
    "    # save information about vertices in settings file\n",
    "    # save y coordinates (row coordinates)\n",
    "    settings.loc[dir_start+i+1, 5] = \" \".join([str(elem[0]) for elem in vertices_list[i]])\n",
    "    # save x coordinates (column coordinates)\n",
    "    settings.loc[dir_start+i+1, 4] = \" \".join([str(elem[1]) for elem in vertices_list[i]])\n",
    "    # save settings file with coordinates of vertices\n",
    "    settings.to_csv(settings_file, index=None, header=None)\n",
    "else:\n",
    "    # extract coordinates from directory input\n",
    "    xs = [int(elem) for elem in directories.loc[i, \"vertices_x\"].split(\" \")]\n",
    "    ys = [int(elem) for elem in directories.loc[i, \"vertices_y\"].split(\" \")]\n",
    "\n",
    "    # add extracted coordinates to list of vertices\n",
    "    vertices_list[i] = np.array([[a, b] for a, b in zip(ys, xs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv2.imread(d, -1) for d in image_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create adata object in 'Dbit-seq' mode\n",
      "Read transcriptome matrix from N:\\01 HPC\\03 Team Meier\\08_Projects\\37_Spatial_Barcoding\\37_30\\data\\raw_matrices\\wells\\A1\\DGE_matrix_with_introns_min100.txt.gz...\n",
      "Compute coordinates...\n",
      "14x4\n",
      "Align and create image metadata...\n",
      "     Align images...\n",
      "[ 1560 10565 10176  1175]\n",
      "[ 1560 10565 10176  1175]\n",
      "[ 1560 10565 10176  1175]\n",
      "[ 1560 10565 10176  1175]\n",
      "     Create metadata...\n",
      "     Summarized aligned images and metadata.\n",
      "Adata object generated.\n",
      "Saving adata object...\n",
      "Adata object saved into N:\\01 HPC\\03 Team Meier\\08_Projects\\37_Spatial_Barcoding\\37_30\\data\\anndata\\37_30_adata_raw_with_images_A1.h5ad\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "db.dbitseq_to_squidpy(matrix_path=matrix_file, images=images,\n",
    "    resolution=int(parameters.loc[\"spot_width\"]), \n",
    "    n_channels=int(parameters.loc[\"n_channels\"]), \n",
    "    frame=int(parameters.loc[\"frame\"]),\n",
    "    dbitx=False, labels=channel_labels, vertices=vertices_list[i], \n",
    "    savepath=output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "well_id = 0\n",
    "alignment_id = 1\n",
    "image_names = ['bf', 'align', 'phalloidin', 'dapi']\n",
    "\n",
    "# image path\n",
    "#image_path = r\"N:\\01 HPC\\03 Team Meier\\10_Resources\\08_Johannes Wirth\\Nextcloud\\DbitX\\data\\37_30\\images\"\n",
    "image_path = \"/Users/Johannes/Nextcloud/DbitX/data/37_30/images/\"\n",
    "\n",
    "# transcriptome path\n",
    "matrix_file = r\"N:\\01 HPC\\03 Team Meier\\10_Resources\\08_Johannes Wirth\\Nextcloud\\DbitX\\data\\37_30\\transcriptome\\wells\\A1\\DGE_matrix_with_introns_min100.txt.gz\"\n",
    "\n",
    "# output directory\n",
    "output_name = \"37_28_adata_raw_with_images.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image names\n",
    "well_names = os.listdir(image_path)\n",
    "well_name = well_names[well_id]\n",
    "image_names = os.listdir(os.path.join(image_path,well_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "images = [cv2.imread(os.path.join(image_path, well_name, name), -1) for name in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_image = images[alignment_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select corner spots in alignment image using napari viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(alignment_image, title=\"Select corner spots in alignment image of well \" + well_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pivot spot and calibration points from viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch vertices (center points of )\n",
    "corner_spots_center = viewer.layers[\"Points\"].data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values from 37_28\n",
    "#corner_spots_center = np.array([[ 486,  990],[ 891, 8662], [8567, 8324],[8164,  646]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata with images and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read transcriptome matrix...\n",
      "Align and create image metadata...\n",
      "     Align images...\n",
      "     Create metadata...\n",
      "     Summarized aligned images and metadata...\n",
      "Compute coordinates...\n",
      "Adata object generated.\n",
      "Saving image...\n",
      "Adata object saved into N:\\01 HPC\\03 Team Meier\\10_Resources\\08_Johannes Wirth\\Nextcloud\\DbitX\\data\\37_30\\images\\A1\\37_28_adata_raw_with_images.h5ad\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "savepath = os.path.join(well_path, output_name)\n",
    "\n",
    "adata = db.dbitseq_to_squidpy(matrix_path=matrix_file, images=images, labels=image_names, vertices=corner_spots_center, \n",
    "                              resolution=50, n_channels=38, frame=100, savepath=savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write total data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(os.path.join(well_path, output_name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "293505d82a019439b957ad4aaaeadb595d5f043ec5f7f0d7434bbbe946c5230f"
  },
  "kernelspec": {
   "display_name": "Python 3 (spatial)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
